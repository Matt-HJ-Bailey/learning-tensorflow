{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "written-victoria",
   "metadata": {},
   "source": [
    "# CNNs\n",
    "Here, we improve the Fashion-MNIST dataset to use a CNN as opposed to the neural network that I used in the last exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "assigned-assist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "pleased-employer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"import tensorflow as tf\\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\\n\\ntfds.disable_progress_bar()\\nimport os\\nimport math\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nimport logging\\n\\nlogger = tf.get_logger()\\nlogger.setLevel(logging.ERROR)\\n\\nphysical_devices = tf.config.list_physical_devices(\\\"GPU\\\")\\ntf.config.experimental.set_memory_growth(physical_devices[0], True)\\nprint(physical_devices)\";\n",
       "                var nbb_formatted_code = \"import tensorflow as tf\\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\\n\\ntfds.disable_progress_bar()\\nimport os\\nimport math\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nimport logging\\n\\nlogger = tf.get_logger()\\nlogger.setLevel(logging.ERROR)\\n\\nphysical_devices = tf.config.list_physical_devices(\\\"GPU\\\")\\ntf.config.experimental.set_memory_growth(physical_devices[0], True)\\nprint(physical_devices)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "tfds.disable_progress_bar()\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "\n",
    "logger = tf.get_logger()\n",
    "logger.setLevel(logging.ERROR)\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "print(physical_devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "novel-understanding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"def normalise(images, labels):\\n    \\\"\\\"\\\"\\n    Normalise the pixel values of a series of images to be in the [0, 1) range.\\n    \\\"\\\"\\\"\\n    images = tf.cast(images, tf.float32)\\n    images /= 255\\n    return images, labels\";\n",
       "                var nbb_formatted_code = \"def normalise(images, labels):\\n    \\\"\\\"\\\"\\n    Normalise the pixel values of a series of images to be in the [0, 1) range.\\n    \\\"\\\"\\\"\\n    images = tf.cast(images, tf.float32)\\n    images /= 255\\n    return images, labels\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def normalise(images, labels):\n",
    "    \"\"\"\n",
    "    Normalise the pixel values of a series of images to be in the [0, 1) range.\n",
    "    \"\"\"\n",
    "    images = tf.cast(images, tf.float32)\n",
    "    images /= 255\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "center-binding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"_URL = \\\"https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\\\"\\nzip_dir = tf.keras.utils.get_file(\\n    \\\"cats_and_dogs_filterted.zip\\\", origin=_URL, extract=True\\n)\\nbase_dir = os.path.join(os.path.dirname(zip_dir), 'cats_and_dogs_filtered')\\ntrain_dir = os.path.join(base_dir, 'train')\\nvalidation_dir = os.path.join(base_dir, 'validation')\\n\\ntrain_cats_dir = os.path.join(train_dir, 'cats')  # directory with our training cat pictures\\ntrain_dogs_dir = os.path.join(train_dir, 'dogs')  # directory with our training dog pictures\\nvalidation_cats_dir = os.path.join(validation_dir, 'cats')  # directory with our validation cat pictures\\nvalidation_dogs_dir = os.path.join(validation_dir, 'dogs')  # directory with our validation dog pictures\";\n",
       "                var nbb_formatted_code = \"_URL = \\\"https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\\\"\\nzip_dir = tf.keras.utils.get_file(\\n    \\\"cats_and_dogs_filterted.zip\\\", origin=_URL, extract=True\\n)\\nbase_dir = os.path.join(os.path.dirname(zip_dir), \\\"cats_and_dogs_filtered\\\")\\ntrain_dir = os.path.join(base_dir, \\\"train\\\")\\nvalidation_dir = os.path.join(base_dir, \\\"validation\\\")\\n\\ntrain_cats_dir = os.path.join(\\n    train_dir, \\\"cats\\\"\\n)  # directory with our training cat pictures\\ntrain_dogs_dir = os.path.join(\\n    train_dir, \\\"dogs\\\"\\n)  # directory with our training dog pictures\\nvalidation_cats_dir = os.path.join(\\n    validation_dir, \\\"cats\\\"\\n)  # directory with our validation cat pictures\\nvalidation_dogs_dir = os.path.join(\\n    validation_dir, \\\"dogs\\\"\\n)  # directory with our validation dog pictures\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset, metadata = tfds.load(\"fashion_mnist\", as_supervised=True, with_info=True)\n",
    "class_names = metadata.features[\"label\"].names\n",
    "train_dataset, test_dataset = dataset[\"train\"], dataset[\"test\"]\n",
    "train_dataset = train_dataset.map(normalise).cache()\n",
    "test_dataset = test_dataset.map(normalise).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "optimum-korean",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training cat images: 1000\n",
      "total training dog images: 1000\n",
      "total validation cat images: 500\n",
      "total validation dog images: 500\n",
      "--\n",
      "Total training images: 2000\n",
      "Total validation images: 1000\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"num_cats_tr = len(os.listdir(train_cats_dir))\\nnum_dogs_tr = len(os.listdir(train_dogs_dir))\\n\\nnum_cats_val = len(os.listdir(validation_cats_dir))\\nnum_dogs_val = len(os.listdir(validation_dogs_dir))\\n\\ntotal_train = num_cats_tr + num_dogs_tr\\ntotal_val = num_cats_val + num_dogs_val\\n\\nprint('total training cat images:', num_cats_tr)\\nprint('total training dog images:', num_dogs_tr)\\n\\nprint('total validation cat images:', num_cats_val)\\nprint('total validation dog images:', num_dogs_val)\\nprint(\\\"--\\\")\\nprint(\\\"Total training images:\\\", total_train)\\nprint(\\\"Total validation images:\\\", total_val)\";\n",
       "                var nbb_formatted_code = \"num_cats_tr = len(os.listdir(train_cats_dir))\\nnum_dogs_tr = len(os.listdir(train_dogs_dir))\\n\\nnum_cats_val = len(os.listdir(validation_cats_dir))\\nnum_dogs_val = len(os.listdir(validation_dogs_dir))\\n\\ntotal_train = num_cats_tr + num_dogs_tr\\ntotal_val = num_cats_val + num_dogs_val\\n\\nprint(\\\"total training cat images:\\\", num_cats_tr)\\nprint(\\\"total training dog images:\\\", num_dogs_tr)\\n\\nprint(\\\"total validation cat images:\\\", num_cats_val)\\nprint(\\\"total validation dog images:\\\", num_dogs_val)\\nprint(\\\"--\\\")\\nprint(\\\"Total training images:\\\", total_train)\\nprint(\\\"Total validation images:\\\", total_val)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cosmetic-argument",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"model = tf.keras.Sequential(\\n    [\\n        tf.keras.layers.Conv2D(\\n            32, (3, 3), padding=\\\"same\\\", activation=tf.nn.relu, input_shape=(28, 28, 1)\\n        ),\\n        tf.keras.layers.MaxPooling2D((2, 2), strides=2),\\n        tf.keras.layers.Conv2D(64, (3, 3), padding=\\\"same\\\", activation=tf.nn.relu),\\n        tf.keras.layers.MaxPooling2D((2, 2), strides=2),\\n        tf.keras.layers.Flatten(),\\n        tf.keras.layers.Dense(128, activation=tf.nn.relu),\\n        tf.keras.layers.Dense(len(class_names)),\\n    ]\\n)\\nmodel.compile(\\n    optimizer=\\\"adam\\\",\\n    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\\n    metrics=[\\\"accuracy\\\"],\\n)\";\n",
       "                var nbb_formatted_code = \"model = tf.keras.Sequential(\\n    [\\n        tf.keras.layers.Conv2D(\\n            32, (3, 3), padding=\\\"same\\\", activation=tf.nn.relu, input_shape=(28, 28, 1)\\n        ),\\n        tf.keras.layers.MaxPooling2D((2, 2), strides=2),\\n        tf.keras.layers.Conv2D(64, (3, 3), padding=\\\"same\\\", activation=tf.nn.relu),\\n        tf.keras.layers.MaxPooling2D((2, 2), strides=2),\\n        tf.keras.layers.Flatten(),\\n        tf.keras.layers.Dense(128, activation=tf.nn.relu),\\n        tf.keras.layers.Dense(len(class_names)),\\n    ]\\n)\\nmodel.compile(\\n    optimizer=\\\"adam\\\",\\n    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\\n    metrics=[\\\"accuracy\\\"],\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Conv2D(\n",
    "            32, (3, 3), padding=\"same\", activation=tf.nn.relu, input_shape=(28, 28, 1)\n",
    "        ),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2), strides=2),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), padding=\"same\", activation=tf.nn.relu),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2), strides=2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(len(class_names)),\n",
    "    ]\n",
    ")\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "veterinary-retrieval",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"BATCH_SIZE = 32\\nnum_train_examples = metadata.splits[\\\"train\\\"].num_examples\\nnum_test_examples = metadata.splits[\\\"test\\\"].num_examples\\ntrain_dataset = (\\n    train_dataset.cache().repeat().shuffle(num_train_examples).batch(BATCH_SIZE)\\n)\\ntest_dataset = test_dataset.cache().batch(BATCH_SIZE)\";\n",
       "                var nbb_formatted_code = \"BATCH_SIZE = 32\\nnum_train_examples = metadata.splits[\\\"train\\\"].num_examples\\nnum_test_examples = metadata.splits[\\\"test\\\"].num_examples\\ntrain_dataset = (\\n    train_dataset.cache().repeat().shuffle(num_train_examples).batch(BATCH_SIZE)\\n)\\ntest_dataset = test_dataset.cache().batch(BATCH_SIZE)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "num_train_examples = metadata.splits[\"train\"].num_examples\n",
    "num_test_examples = metadata.splits[\"test\"].num_examples\n",
    "train_dataset = (\n",
    "    train_dataset.cache().repeat().shuffle(num_train_examples).batch(BATCH_SIZE)\n",
    ")\n",
    "test_dataset = test_dataset.cache().batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "expected-technology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1293 - accuracy: 0.9523\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1108 - accuracy: 0.9596\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0972 - accuracy: 0.9637\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0810 - accuracy: 0.9696\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0669 - accuracy: 0.9757\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0583 - accuracy: 0.9785\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0512 - accuracy: 0.9809\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0420 - accuracy: 0.9844\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0372 - accuracy: 0.9861\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0336 - accuracy: 0.9883\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.4377 - accuracy: 0.9197\n",
      "Accuracy on test dataset: 0.919700026512146\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"model.fit(\\n    train_dataset, epochs=10, steps_per_epoch=math.ceil(num_train_examples / BATCH_SIZE)\\n)\\ntest_loss, test_accuracy = model.evaluate(\\n    test_dataset, steps=math.ceil(num_test_examples / 32)\\n)\\nprint(\\\"Accuracy on test dataset:\\\", test_accuracy)\";\n",
       "                var nbb_formatted_code = \"model.fit(\\n    train_dataset, epochs=10, steps_per_epoch=math.ceil(num_train_examples / BATCH_SIZE)\\n)\\ntest_loss, test_accuracy = model.evaluate(\\n    test_dataset, steps=math.ceil(num_test_examples / 32)\\n)\\nprint(\\\"Accuracy on test dataset:\\\", test_accuracy)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_dataset, epochs=10, steps_per_epoch=math.ceil(num_train_examples / BATCH_SIZE)\n",
    ")\n",
    "test_loss, test_accuracy = model.evaluate(\n",
    "    test_dataset, steps=math.ceil(num_test_examples / 32)\n",
    ")\n",
    "print(\"Accuracy on test dataset:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endangered-disposition",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applicable-attitude",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
